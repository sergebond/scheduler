*  scheduler
   
   Для запуска

   #+BEGIN_SRC
   rebar compile&&./start.sh
   #+END_SRC

   Для запуска бенчмарка 
   
   #+BEGIN_SRC
   scheduler:benchmark().
   #+END_SRC
   
** API
   
   #+BEGIN_SRC
   -spec scheduler:schedule(TaskID :: binary(), PID :: integer(),
             Type :: static|dynamic,
             Time :: {rel, integer()}|integer()) -> ok.
             
   -spec scheduler:unschedule(TaskID :: binary(), PID :: integer()) -> ok.     
   #+END_SRC
  
   
** architecture
   Cупервизор scheduler_sup со стратегией one_for_all запускает два воркера scheduler_srv и aggregator_srv и дочерний супервизор queue_sup 
   scheduler_srv - пул очередей, запускает воркер queue_srv для каждого нового processID из под супервизора queue_sup (simple_one_for_one). agregator_srv - воркер, собирает "излишки данных" из очередей и через промежуток времени ложит в базу.

** task

   Реализовать приложение для вызова событий по времени.


   Приложение должно работать с относительной и абсолютной величинами таймингов
   Текущее время + относительная часть(например 30 сек)
   Абсолютная (сработать, например, 01.01.2016)


   Приложение должно иметь апи:
      1)для приема заявок. Входные параметры:
   ID задачи (varchar)
   ID процесса (integer)
   тип(статика/динамика)
   время(integer) 
      2) для удаления событий. Входные параметры:
   ID задачи (varchar)
   ID процесса (integer)


   При приеме нового события с одним и тем же (ID задачи, ID процесса) прошлый нужно перезатирать. При удалении события    вызываться при срабатывании time оно уже не должно.


   Общение с основным приложением будет на уровне очереди(rabbitMQ), при срабатывании события необходимо бросить в очередь rabbitMQ событие(в спецификации очереди есть параметр reply-to, который укажет в какую очередь отправить ответ), куда включить ID задачи и ID процесса (для примера {call_timer, ProcID, TaskID}).


Для экономии памяти необходима гибридная схема: храним N задач по процессу, остальное в базе. Когда очередь задач по процессу иссякла, идем в базу и набираем еще порцию данных.


Для уменьшения запросов в БД необходимо агрегировать запросы в базу(чтобы не случилось так, что 1000 обработчиков захотели получить данные в единицу времени).


Приложение должно с легкостью управляться с нагрузкой - 20тысяч приемов новых заявок и 20 тысяч удалений в секунду одновременно. Время срабатывания события критично до секунды.


Выполнять задание в репозитории типа github. Использовать тесты.
